{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 載入MNIST手寫數字數據集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\",one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定義模型函式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape, name):\n",
    "    return tf.Variable(tf.truncated_normal(shape = shape, stddev = 0.1), name = name)\n",
    "\n",
    "def bias_variable(shape, name):\n",
    "    return tf.Variable(tf.constant(0.1, shape = shape),name = name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 參數定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "G_DIM = 128\n",
    "X_D = tf.placeholder(tf.float32,[None, 784])\n",
    "X_G = tf.placeholder(tf.float32,[None, 128])\n",
    "\n",
    "weights = {\n",
    "    \"w_d1\":weight_variable([784,128],'w_d1'),\n",
    "    \"w_d2\":weight_variable([128,1],'w_d2'),\n",
    "    'w_g1':weight_variable([128,256],'w_g1'),\n",
    "    'w_g2':weight_variable([256,784],'w_g2')\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'b_d1':bias_variable([128],'b_d1'),\n",
    "    'b_d2':bias_variable([1],'b_d2'),\n",
    "    'b_g1':bias_variable([256],'b_g1'),\n",
    "    'b_g2':bias_variable([784],'b_g2')\n",
    "}\n",
    "\n",
    "var_d = [weights['w_d1'], weights['w_d2'], biases['b_d1'], biases['b_d2']]\n",
    "var_g = [weights['w_g1'], weights['w_g2'], biases['b_g1'], biases['b_g2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定義生成與對抗網路函式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(z):\n",
    "    h_g1 = tf.nn.relu(tf.add(tf.matmul(z, weights['w_g1']), biases['b_g1']))\n",
    "    h_g2 = tf.nn.sigmoid(tf.add(tf.matmul(h_g1, weights['w_g2']), biases['b_g2']))\n",
    "    \n",
    "    return h_g2\n",
    "\n",
    "def discriminator(x):\n",
    "    h_d1 = tf.nn.relu(tf.add(tf.matmul(x, weights['w_d1']), biases['b_d1']))\n",
    "    h_d2 = tf.nn.sigmoid(tf.add(tf.matmul(h_d1, weights['w_d2']), biases['b_d2']))\n",
    "    \n",
    "    return h_d2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 損失函數與優化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_z(m, n):\n",
    "    return np.random.uniform(-1.,1., size = [m,n])\n",
    "\n",
    "g_sample = generator(X_G)\n",
    "d_real = discriminator(X_D)\n",
    "d_predict = discriminator(g_sample)\n",
    "\n",
    "d_loss = -tf.reduce_mean(tf.log(d_real) + tf.log(1. - d_predict))\n",
    "g_loss = -tf.reduce_mean(tf.log(d_predict))\n",
    "\n",
    "\n",
    "\n",
    "d_opt = tf.train.AdamOptimizer(0.0005).minimize(d_loss, var_list = var_d)\n",
    "g_opt = tf.train.AdamOptimizer(0.0001).minimize(g_loss, var_list = var_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 實例化執行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:0,d_loss:1.293395757675171,g_loss:2.4811692237854004\n",
      "Step:1000,d_loss:0.012302594259381294,g_loss:5.603867530822754\n",
      "Step:2000,d_loss:0.02856394462287426,g_loss:5.653247833251953\n",
      "Step:3000,d_loss:0.015586093999445438,g_loss:7.324066162109375\n",
      "Step:4000,d_loss:0.02663254365324974,g_loss:5.903477668762207\n",
      "Step:5000,d_loss:0.02850026823580265,g_loss:6.719682216644287\n",
      "Step:6000,d_loss:0.037759073078632355,g_loss:7.297340393066406\n",
      "Step:7000,d_loss:0.03580639883875847,g_loss:7.952790260314941\n",
      "Step:8000,d_loss:0.08058644086122513,g_loss:6.650460243225098\n",
      "Step:9000,d_loss:0.0626363754272461,g_loss:6.963033676147461\n",
      "Step:10000,d_loss:0.1053246259689331,g_loss:5.9197678565979\n",
      "Step:11000,d_loss:0.14665135741233826,g_loss:5.885573387145996\n",
      "Step:12000,d_loss:0.14797133207321167,g_loss:5.649303436279297\n",
      "Step:13000,d_loss:0.18788129091262817,g_loss:5.428991317749023\n",
      "Step:14000,d_loss:0.20852303504943848,g_loss:5.641643524169922\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(15000):\n",
    "        batchx = mnist.train.next_batch(BATCH_SIZE)[0]\n",
    "        \n",
    "        _,d_loss_train = sess.run([d_opt, d_loss], feed_dict = {X_D : batchx, X_G : sample_z(BATCH_SIZE, G_DIM)})\n",
    "        \n",
    "        _,g_loss_train = sess.run([g_opt, g_loss], feed_dict = {X_G : sample_z(BATCH_SIZE, G_DIM)})\n",
    "        \n",
    "        if step%1000 == 0:\n",
    "            print(\"Step:{},d_loss:{},g_loss:{}\".format(step,d_loss_train,g_loss_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
